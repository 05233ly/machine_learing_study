{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程介绍了如何使用Estimators解决TensorFlow中的虹膜分类问题。Estimator是TensorFlow完整模型的高级表示，其设计目的是易于缩放和异步训练。有关更多详细信息，请参见 Estimators。\n",
    "\n",
    "请注意，在TensorFlow 2.0中，Keras API可以完成许多相同的任务，并且被认为是更容易学习的API。如果您是从头开始，我们建议您从Keras开始。有关TensorFlow 2.0中可用的高级API的更多信息，请参阅《在Keras上标准化》。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一件事\n",
    "\n",
    "为了开始，您将首先导入TensorFlow和您需要的许多库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集\n",
    "本文档中的示例程序构建并测试了一个模型，该模型根据鸢尾花的萼片和 花瓣的大小将其分为三个不同的物种 。\n",
    "\n",
    "您将使用虹膜数据集训练模型。虹膜数据集包含四个要素和一个 标签。这四个特征确定了单个鸢尾花的以下植物学特征：\n",
    "\n",
    "* 萼片长度\n",
    "* 萼片宽度\n",
    "* 花瓣长度\n",
    "* 花瓣宽度\n",
    "\n",
    "根据此信息，您可以定义一些有用的常量来解析数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，使用Keras和Pandas下载并解析Iris数据集。请注意，您保留了不同的数据集以进行培训和测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以检查数据以查看具有四个float功能列和一个int32标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每个数据集，请分割标签，模型将被训练以进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "# The label column has now been removed from the features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "估计器编程概述<br>\n",
    "现在您已经设置了数据，您可以使用TensorFlow Estimator定义模型。估算器是从派生的任何类tf.estimator.Estimator。TensorFlow提供了tf.estimator （例如LinearRegressor）的集合 来实现常见的ML算法。除此以外，您还可以编写自己的 自定义估算器。我们建议刚开始时使用预制的估算器。\n",
    "\n",
    "要基于预制的Estimators编写TensorFlow程序，您必须执行以下任务：\n",
    "\n",
    "* 创建一个或多个输入函数。\n",
    "* 定义模型的特征列。\n",
    "* 实例化一个估计器，指定要素列和各种超参数。\n",
    "* 在Estimator对象上调用一个或多个方法，并传递适当的输入函数作为数据源。\n",
    "\n",
    "让我们看看如何为虹膜分类执行这些任务。\n",
    "\n",
    "创建输入功能<br>\n",
    "您必须创建输入函数以提供用于训练，评估和预测的数据。\n",
    "\n",
    "一个输入功能是返回的函数tf.data.Dataset，输出以下两个元素的元组对象：\n",
    "\n",
    "* features -Python字典，其中：\n",
    "    * 每个键都是功能的名称。\n",
    "    * 每个值都是一个包含该要素所有值的数组。\n",
    "* label-包含每个示例的标签值的数组 。\n",
    "\n",
    "只是为了演示输入函数的格式，下面是一个简单的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您的输入函数可以生成features字典并label以您喜欢的任何方式列出。但是，我们建议使用TensorFlow的Dataset API，它可以解析各种数据。\n",
    "\n",
    "Dataset API可以为您处理许多常见情况。例如，使用Dataset API，您可以轻松并行地从大量文件中读取记录，并将它们加入单个流中。\n",
    "\n",
    "为了使示例简单，您将使用pandas加载数据 ，并根据此内存数据构建输入管道："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义特征列\n",
    "一个特征柱 是描述如何模型应该从特征字典使用原始输入数据的对象。构建Estimator模型时，会向其传递一系列功能列，这些列描述了您希望模型使用的每个功能。该tf.feature_column模块提供了许多用于表示模型数据的选项。\n",
    "\n",
    "对于Iris，这4个原始特征是数值，因此我们将构建一个特征列列表，以告知Estimator模型将这四个特征中的每一个表示为32位浮点值。因此，用于创建功能部件列的代码为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "功能列可能比我们在此处显示的功能列复杂得多。您可以在本指南中阅读有关功能列的更多信息。\n",
    "\n",
    "现在，您已经有了关于如何使模型表示原始特征的描述，您可以构建估计器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化估算器\n",
    "虹膜问题是经典的分类问题。幸运的是，TensorFlow提供了几个预制的分类器估计器，包括：\n",
    "\n",
    "* tf.estimator.DNNClassifier 适用于执行多类别分类的深层模型。\n",
    "* tf.estimator.DNNLinearCombinedClassifier 适用于宽模型和深模型。\n",
    "* tf.estimator.LinearClassifier 用于基于线性模型的分类器。\n",
    "\n",
    "对于虹膜问题，tf.estimator.DNNClassifier似乎是最佳选择。实例化此估算器的方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\30660\\AppData\\Local\\Temp\\tmpntldugyk\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\30660\\\\AppData\\\\Local\\\\Temp\\\\tmpntldugyk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021EB102F748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练，评估和预测\n",
    "现在有了Estimator对象，您可以调用方法来执行以下操作：\n",
    "\n",
    "* 训练模型。\n",
    "* 评估训练后的模型。\n",
    "* 使用训练有素的模型进行预测。\n",
    "\n",
    "训练模型<br>\n",
    "通过调用Estimator的train方法训练模型，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\30660\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adagrad.py:108: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\30660\\AppData\\Local\\Temp\\tmpntldugyk\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8407391, step = 0\n",
      "INFO:tensorflow:global_step/sec: 259.76\n",
      "INFO:tensorflow:loss = 1.1836618, step = 100 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.426\n",
      "INFO:tensorflow:loss = 1.0864959, step = 200 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.221\n",
      "INFO:tensorflow:loss = 1.0311152, step = 300 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.318\n",
      "INFO:tensorflow:loss = 0.99741894, step = 400 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.569\n",
      "INFO:tensorflow:loss = 0.96295863, step = 500 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.529\n",
      "INFO:tensorflow:loss = 0.9404888, step = 600 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.794\n",
      "INFO:tensorflow:loss = 0.92008805, step = 700 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 0.89670205, step = 800 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.359\n",
      "INFO:tensorflow:loss = 0.8802767, step = 900 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.426\n",
      "INFO:tensorflow:loss = 0.86061907, step = 1000 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.221\n",
      "INFO:tensorflow:loss = 0.8476548, step = 1100 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.359\n",
      "INFO:tensorflow:loss = 0.8301133, step = 1200 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.425\n",
      "INFO:tensorflow:loss = 0.819895, step = 1300 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.515\n",
      "INFO:tensorflow:loss = 0.8054925, step = 1400 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.335\n",
      "INFO:tensorflow:loss = 0.78702086, step = 1500 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.154\n",
      "INFO:tensorflow:loss = 0.7761853, step = 1600 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.627\n",
      "INFO:tensorflow:loss = 0.7692497, step = 1700 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.302\n",
      "INFO:tensorflow:loss = 0.7541733, step = 1800 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.01\n",
      "INFO:tensorflow:loss = 0.7353766, step = 1900 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.627\n",
      "INFO:tensorflow:loss = 0.7280184, step = 2000 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.468\n",
      "INFO:tensorflow:loss = 0.7164674, step = 2100 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.533\n",
      "INFO:tensorflow:loss = 0.7111486, step = 2200 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.55\n",
      "INFO:tensorflow:loss = 0.6962589, step = 2300 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.306\n",
      "INFO:tensorflow:loss = 0.6868556, step = 2400 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.53\n",
      "INFO:tensorflow:loss = 0.67241263, step = 2500 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.359\n",
      "INFO:tensorflow:loss = 0.66448206, step = 2600 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 0.6571788, step = 2700 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.841\n",
      "INFO:tensorflow:loss = 0.64410627, step = 2800 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.323\n",
      "INFO:tensorflow:loss = 0.6412291, step = 2900 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.425\n",
      "INFO:tensorflow:loss = 0.6321666, step = 3000 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.459\n",
      "INFO:tensorflow:loss = 0.62220037, step = 3100 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.3\n",
      "INFO:tensorflow:loss = 0.6176441, step = 3200 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 0.6017673, step = 3300 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.131\n",
      "INFO:tensorflow:loss = 0.59338605, step = 3400 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.039\n",
      "INFO:tensorflow:loss = 0.58661467, step = 3500 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.694\n",
      "INFO:tensorflow:loss = 0.5864595, step = 3600 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.922\n",
      "INFO:tensorflow:loss = 0.5748011, step = 3700 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.301\n",
      "INFO:tensorflow:loss = 0.56522685, step = 3800 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.628\n",
      "INFO:tensorflow:loss = 0.555095, step = 3900 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.747\n",
      "INFO:tensorflow:loss = 0.53980577, step = 4000 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.318\n",
      "INFO:tensorflow:loss = 0.5499404, step = 4100 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.034\n",
      "INFO:tensorflow:loss = 0.540161, step = 4200 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.202\n",
      "INFO:tensorflow:loss = 0.5255088, step = 4300 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.301\n",
      "INFO:tensorflow:loss = 0.5217681, step = 4400 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.516\n",
      "INFO:tensorflow:loss = 0.51582175, step = 4500 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.249\n",
      "INFO:tensorflow:loss = 0.51136166, step = 4600 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.323\n",
      "INFO:tensorflow:loss = 0.50467795, step = 4700 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 0.50045294, step = 4800 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.081\n",
      "INFO:tensorflow:loss = 0.4893612, step = 4900 (0.338 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\30660\\AppData\\Local\\Temp\\tmpntldugyk\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.48913935.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x21eb102feb8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，您将input_fn调用包装在中 lambda 以捕获参数，同时提供了一个不包含参数的输入函数，这是Estimator期望的。该steps参数告诉方法在许多训练步骤后停止训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-10-15T18:41:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\30660\\AppData\\Local\\Temp\\tmpntldugyk\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-10-15-18:41:06\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.96666664, average_loss = 0.52841496, global_step = 5000, loss = 0.52841496\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\30660\\AppData\\Local\\Temp\\tmpntldugyk\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估训练好的模型<br>\n",
    "现在已经对模型进行了训练，您可以获取有关其性能的一些统计信息。以下代码块根据测试数据评估训练模型的准确性："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据训练后的模型进行预测（推断）\n",
    "\n",
    "您现在拥有一个训练有素的模型，该模型可以产生良好的评估结果。现在，您可以使用训练有素的模型，根据一些未标记的测量值来预测鸢尾花的种类。与培训和评估一样，您可以使用单个函数调用进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该predict方法返回Python迭代的，为每个示例生成预测结果字典。以下代码显示了一些预测及其概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\30660\\AppData\\Local\\Temp\\tmpntldugyk\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (67.7%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (50.2%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (55.7%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
