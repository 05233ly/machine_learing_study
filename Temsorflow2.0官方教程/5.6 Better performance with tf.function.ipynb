{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在TensorFlow 2.0中，渴望执行默认情况下处于打开状态。用户界面直观且灵活（运行一次性操作要容易得多且更快），但这可能会牺牲性能和可部署性。\n",
    "\n",
    "为了获得最佳性能并使模型可部署到任何地方，请使用 tf.function从程序中制作图表。多亏了AutoGraph，tf.function才可以使用数量惊人的Python代码，但是仍然要提防一些陷阱。\n",
    "\n",
    "主要要点和建议是：\n",
    "\n",
    "* 不要依赖于Python的副作用，例如对象突变或列表追加。\n",
    "* tf.function最适合TensorFlow操作，而不是NumPy操作或Python原语。\n",
    "* 如有疑问，请使用for x in y成语。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "# Some helper code to demonstrate the kinds of errors you might encounter.\n",
    "@contextlib.contextmanager\n",
    "def assert_raises(error_class):\n",
    "    try:\n",
    "        yield\n",
    "    except error_class as e:\n",
    "        print('Caught expected exception \\n  {}: {}'.format(error_class, e))\n",
    "    except Exception as e:\n",
    "        print('Got unexpected exception \\n  {}: {}'.format(type(e), e))\n",
    "    else:\n",
    "        raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
    "            error_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.function您定义的A 就像核心TensorFlow操作：您可以急切地执行它；您可以在图形中使用它；它具有渐变；等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function is like an op\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=38, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions have gradients\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=64, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use functions inside functions\n",
    "\n",
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "    return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追踪和多态<br>\n",
    "Python的动态类型化意味着您可以使用各种参数类型来调用函数，并且Python在每种情况下都会做不同的事情。\n",
    "\n",
    "另一方面，TensorFlow图需要静态dtypes和形状尺寸。tf.function通过在必要时重新生成功能图来缩小差距。使用的大多数微妙之处都tf.function来自这种追溯行为。\n",
    "\n",
    "您可以调用带有不同类型参数的函数以查看发生了什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Functions are polymorphic\n",
    "\n",
    "@tf.function\n",
    "def double(a):\n",
    "    print(\"Tracing with\", a)\n",
    "    return a + a\n",
    "\n",
    "print(double(tf.constant(1)))\n",
    "print()\n",
    "print(double(tf.constant(1.1)))\n",
    "print()\n",
    "print(double(tf.constant(\"a\")))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若要控制跟踪行为，请使用以下技术：\n",
    "\n",
    "* 创建一个新的tf.function。tf.function保证单独的对象不共享跟踪。\n",
    "* 使用该get_concrete_function方法获取特定的跟踪\n",
    "* 指定input_signature在调用tf.function时仅对每个调用图跟踪一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining concrete trace\n",
      "Tracing with Tensor(\"a:0\", dtype=string)\n",
      "Executing traced function\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "tf.Tensor(b'bb', shape=(), dtype=string)\n",
      "Using a concrete trace with incompatible types will throw an error\n",
      "Caught expected exception \n",
      "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>: cannot compute __inference_double_91 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_91]\n"
     ]
    }
   ],
   "source": [
    "print(\"Obtaining concrete trace\")\n",
    "double_strings = double.get_concrete_function(tf.TensorSpec(shape=None, dtype=tf.string))\n",
    "print(\"Executing traced function\")\n",
    "print(double_strings(tf.constant(\"a\")))\n",
    "print(double_strings(a=tf.constant(\"b\")))\n",
    "print(\"Using a concrete trace with incompatible types will throw an error\")\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "    double_strings(tf.constant(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>: Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
    "def next_collatz(x):\n",
    "    print(\"Tracing with\", x)\n",
    "    return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
    "\n",
    "print(next_collatz(tf.constant([1, 2])))\n",
    "# We specified a 1-D tensor in the input signature, so this should fail.\n",
    "with assert_raises(ValueError):\n",
    "    next_collatz(tf.constant([[1, 2], [3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么时候回溯？<br>\n",
    "多态tf.function保留了由跟踪生成的具体功能的缓存。缓存键实际上是从函数args和kwargs生成的键的元组。为自tf.Tensor变量生成的键是其形状和类型。为Python原语生成的密钥是其值。对于所有其他Python类型，键都是基于对象的，id()因此对于类的每个实例都独立地跟踪方法。将来，TensorFlow可能会为Python对象添加更复杂的缓存，这些缓存可以安全地转换为张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python或Tensor参数？<br>\n",
    "通常，Python参数用于控制超参数和图形构造-例如num_layers=10or training=True或nonlinearity='relu'。因此，如果Python参数改变，则必须重新绘制图形。\n",
    "\n",
    "但是，可能没有使用Python参数来控制图形的构造。在这些情况下，Python值的更改可能会触发不必要的跟踪。以这个训练循环为例，AutoGraph将动态展开该训练循环。尽管有多条迹线，但生成的图实际上是相同的，因此效率较低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = 10\n",
      "Tracing with num_steps = 20\n"
     ]
    }
   ],
   "source": [
    "def train_one_step():\n",
    "    pass\n",
    "\n",
    "@tf.function\n",
    "def train(num_steps):\n",
    "    print(\"Tracing with num_steps = {}\".format(num_steps))\n",
    "    for _ in tf.range(num_steps):\n",
    "        train_one_step()\n",
    "\n",
    "train(num_steps=10)\n",
    "train(num_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的一个简单的解决方法是，在不影响所生成图形的形状的情况下，将您的参数转换为Tensors。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = Tensor(\"num_steps:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train(num_steps=tf.constant(10))\n",
    "train(num_steps=tf.constant(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "副作用 tf.function<br>\n",
    "通常，Python副作用（如打印或变异对象）仅在跟踪期间发生。那么，如何可靠地从中引发副作用tf.function呢？\n",
    "\n",
    "一般的经验法则是仅使用Python副作用来调试跟踪。否则，TensorFlow操作（如tf.Variable.assign，tf.print和）tf.summary是确保每次调用时TensorFlow运行时都将跟踪和执行代码的最佳方法。通常，使用功能样式会产生最佳效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 1\n",
      "Executed with 1\n",
      "Executed with 1\n",
      "Traced with 2\n",
      "Executed with 2\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    print(\"Traced with\", x)\n",
    "    tf.print(\"Executed with\", x)\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您想在每次调用时执行Python代码tf.function，tf.py_function则为退出舱门。缺点tf.py_function是它不便携或性能不佳，在分布式（多GPU，TPU）设置中也不能很好地工作。同样，由于tf.py_function必须将其连接到图中，因此它将所有输入/输出转换为张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python side effect\n",
      "Python side effect\n",
      "Python side effect\n"
     ]
    }
   ],
   "source": [
    "external_list = []\n",
    "\n",
    "def side_effect(x):\n",
    "    print('Python side effect')\n",
    "    external_list.append(x)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    tf.py_function(side_effect, inp=[x], Tout=[])\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(1)\n",
    "assert len(external_list) == 3\n",
    "# .numpy() call required because py_function casts 1 to tf.constant(1)\n",
    "assert external_list[0].numpy() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当心Python状态<br>\n",
    "许多Python功能（例如生成器和迭代器）都依赖Python运行时来跟踪状态。通常，尽管这些构造在“急切”模式下可以正常工作，但是tf.function由于跟踪行为，内部可能发生许多意外情况。\n",
    "\n",
    "举一个例子，推进迭代器状态是Python的副作用，因此仅在跟踪期间发生。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of external_var: 0\n",
      "Value of external_var: 0\n",
      "Value of external_var: 0\n"
     ]
    }
   ],
   "source": [
    "external_var = tf.Variable(0)\n",
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "    external_var.assign_add(next(iterator))\n",
    "    tf.print(\"Value of external_var:\", external_var)\n",
    "\n",
    "iterator = iter([0, 1, 2, 3])\n",
    "buggy_consume_next(iterator)\n",
    "# This reuses the first value from the iterator, rather than consuming the next value.\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果迭代器是在tf.function中完全生成并使用的，则它应该可以正常工作。但是，可能会跟踪整个迭代器，这可能会导致一个巨大的图。这可能就是您想要的。但是，如果您要在以Python列表表示的大型内存数据集中进行训练，则这可能会生成非常大的图形，并且tf.function不太可能产生加速。\n",
    "\n",
    "如果要遍历Python数据，最安全的方法是将其包装在tf.data.Dataset中并使用该for x in y惯用法。for当y张量或tf.data.Dataset 时，AutoGraph具有对安全转换循环的特殊支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train([(1, 1), (1, 1)]) contains 8 nodes in its graph\n",
      "train([(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]) contains 32 nodes in its graph\n",
      "train(<DatasetV1Adapter shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 5 nodes in its graph\n",
      "train(<DatasetV1Adapter shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 5 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "def measure_graph_size(f, *args):\n",
    "    g = f.get_concrete_function(*args).graph\n",
    "    print(\"{}({}) contains {} nodes in its graph\".format(\n",
    "        f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
    "\n",
    "@tf.function\n",
    "def train(dataset):\n",
    "    loss = tf.constant(0)\n",
    "    for x, y in dataset:\n",
    "        loss += tf.abs(y - x) # Some dummy computation.\n",
    "    return loss\n",
    "\n",
    "small_data = [(1, 1)] * 2\n",
    "big_data = [(1, 1)] * 10\n",
    "measure_graph_size(train, small_data)\n",
    "measure_graph_size(train, big_data)\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: small_data, (tf.int32, tf.int32)))\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: big_data, (tf.int32, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当在数据集的Python包装/ numpy的数据，心的tf.data.Dataset.from_generator对tf.data.Dataset.from_tensors。前者将数据保留在Python中并通过获取数据tf.py_function可能会对性能产生影响，而后者会将数据的副本捆绑为tf.constant()图形中的一个大节点，这可能会影响内存。\n",
    "\n",
    "通过TFRecordDataset / CsvDataset / etc从文件读取数据。是使用数据的最有效方法，因为TensorFlow本身可以管理数据的异步加载和预取，而无需使用Python。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动控制依赖项<br>\n",
    "在一般数据流图上，函数作为编程模型的一个非常吸引人的特性是，函数可以为运行时提供有关代码预期行为的更多信息。\n",
    "\n",
    "例如，当编写具有多个读取和写入相同变量的代码时，数据流图可能无法自然地编码最初预期的操作顺序。在中tf.function，我们通过引用原始Python代码中语句的执行顺序来解决执行顺序中的歧义。这样，有状态操作在tf.function复制中的顺序将复制Eager模式的语义。\n",
    "\n",
    "这意味着无需添加手动控件依赖项。tf.function足够聪明，可以添加最少的必需和足够的控件依赖项集，以使代码正确运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=418, shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatic control dependencies\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "    a.assign(y * b)\n",
    "    b.assign_add(x * a)\n",
    "    return a + b\n",
    "\n",
    "f(1.0, 2.0)  # 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变数<br>\n",
    "我们可以使用相同的想法，利用代码的预期执行顺序来简化变量的创建和使用tf.function。不过，有一个非常重要的警告，那就是使用变量可以编写在渴望模式和图形模式下表现不同的代码。\n",
    "\n",
    "具体来说，当您为每个调用创建一个新的变量时，就会发生这种情况。由于语义的跟踪，tf.function每个调用将重用相同的变量，但是渴望模式将为每个调用创建一个新变量。为防止此错误，tf.function如果它检测到危险的变量创建行为，将引发错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-16-f080b8550f95>:3 f  *\n",
      "        v = tf.Variable(1.0)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:260 __call__\n",
      "        return cls._variable_v2_call(*args, **kwargs)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:254 _variable_v2_call\n",
      "        shape=shape)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:65 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py:413 invalid_creator_scope\n",
      "        \"tf.function-decorated function tried to create \"\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    v = tf.Variable(1.0)\n",
    "    v.assign_add(x)\n",
    "    return v\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "    f(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Non-ambiguous code is ok though\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    return v.assign_add(x)\n",
    "\n",
    "print(f(1.0))  # 2.0\n",
    "print(f(2.0))  # 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# You can also create variables inside a tf.function as long as we can prove\n",
    "# that those variables are created only the first time the function is executed.\n",
    "\n",
    "class C: pass\n",
    "obj = C(); obj.v = None\n",
    "\n",
    "@tf.function\n",
    "def g(x):\n",
    "    if obj.v is None:\n",
    "        obj.v = tf.Variable(1.0)\n",
    "    return obj.v.assign_add(x)\n",
    "\n",
    "print(g(1.0))  # 2.0\n",
    "print(g(2.0))  # 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.0, shape=(), dtype=float32)\n",
      "tf.Tensor(36.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "state = []\n",
    "@tf.function\n",
    "def fn(x):\n",
    "    if not state:\n",
    "        state.append(tf.Variable(2.0 * x))\n",
    "        state.append(tf.Variable(state[0] * 3.0))\n",
    "    return state[0] * x * state[1]\n",
    "\n",
    "print(fn(tf.constant(1.0)))\n",
    "print(fn(tf.constant(3.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自动绘图<br>\n",
    "该签名库完全集成tf.function，它将改写条件和循环依赖于张量在图形动态运行。\n",
    "\n",
    "tf.cond并tf.while_loop继续使用tf.function，但是以命令式方式编写时，具有控制流的代码通常更易于编写和理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.246125817 0.116935611 0.765960574 0.237833142 0.781809807]\n",
      "[0.241273433 0.116405524 0.644574463 0.233448014 0.65374428]\n",
      "[0.236698195 0.11588259 0.568006158 0.229297653 0.574185193]\n",
      "[0.232374638 0.115366645 0.513893485 0.225361779 0.518426299]\n",
      "[0.228280455 0.11485754 0.472973257 0.221622512 0.476484507]\n",
      "[0.22439602 0.114355117 0.440598518 0.218063965 0.443423778]\n",
      "[0.220703989 0.113859236 0.414140433 0.214672014 0.416478395]\n",
      "[0.217188954 0.113369755 0.391982615 0.211434036 0.393959552]\n",
      "[0.213837177 0.112886541 0.373068154 0.208338708 0.374768704]\n",
      "[0.210636377 0.112409458 0.356672466 0.20537582 0.358155787]\n",
      "[0.207575545 0.11193838 0.342279673 0.202536196 0.343588561]\n",
      "[0.20464474 0.11147318 0.329511046 0.199811488 0.33067733]\n",
      "[0.201834992 0.111013733 0.318081349 0.197194144 0.319129258]\n",
      "[0.199138194 0.110559925 0.307771027 0.194677293 0.308719367]\n",
      "[0.196546957 0.110111646 0.298407942 0.192254648 0.299271584]\n",
      "[0.194054559 0.109668776 0.289854974 0.189920455 0.290645868]\n",
      "[0.191654861 0.109231211 0.282001317 0.187669471 0.282729149]\n",
      "[0.189342245 0.108798847 0.274756312 0.185496852 0.27542907]\n",
      "[0.187111557 0.108371586 0.268045 0.183398142 0.268669307]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=675, shape=(5,), dtype=float32, numpy=\n",
       "array([0.18495807, 0.10794932, 0.26180476, 0.18136925, 0.26238617],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('f', 'f_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as f_scope:\n",
      "\n",
      "    def get_state():\n",
      "      return ()\n",
      "\n",
      "    def set_state(_):\n",
      "      pass\n",
      "\n",
      "    def loop_body(x):\n",
      "      ag__.converted_call(tf.print, f_scope.callopts, (x,), None, f_scope)\n",
      "      x = ag__.converted_call(tf.tanh, f_scope.callopts, (x,), None, f_scope)\n",
      "      return x,\n",
      "\n",
      "    def loop_test(x):\n",
      "      return ag__.converted_call(tf.reduce_sum, f_scope.callopts, (x,), None, f_scope) > 1\n",
      "    x, = ag__.while_stmt(loop_test, loop_body, get_state, set_state, (x,), ('x',), ())\n",
      "    do_return = True\n",
      "    retval_ = f_scope.mark_return_value(x)\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you're curious you can inspect the code autograph generates.\n",
    "# It feels like reading assembly language, though.\n",
    "\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph：条件<br>\n",
    "AutoGraph会将if语句转换为等效tf.cond调用。\n",
    "\n",
    "如果条件为张量，则进行此替换。否则，条件将在跟踪期间执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tf_cond(f, *args):\n",
    "    g = f.get_concrete_function(*args).graph\n",
    "    if any(node.name == 'cond' for node in g.as_graph_def().node):\n",
    "        print(\"{}({}) uses tf.cond.\".format(\n",
    "            f.__name__, ', '.join(map(str, args))))\n",
    "    else:\n",
    "        print(\"{}({}) executes normally.\".format(\n",
    "            f.__name__, ', '.join(map(str, args))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparam_cond(tf.Tensor([1.], shape=(1,), dtype=float32)) executes normally.\n",
      "maybe_tensor_cond(tf.Tensor(-1, shape=(), dtype=int32)) uses tf.cond.\n",
      "maybe_tensor_cond(-1) executes normally.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def hyperparam_cond(x, training=True):\n",
    "    if training:\n",
    "        x = tf.nn.dropout(x, rate=0.5)\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def maybe_tensor_cond(x):\n",
    "    if x < 0:\n",
    "        x = -x\n",
    "    return x\n",
    "\n",
    "test_tf_cond(hyperparam_cond, tf.ones([1], dtype=tf.float32))\n",
    "test_tf_cond(maybe_tensor_cond, tf.constant(-1))\n",
    "test_tf_cond(maybe_tensor_cond, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.cond有许多微妙之处。-它通过跟踪条件的两端，然后根据条件在运行时选择适当的分支来工作。跟踪两侧可能会导致Python代码意外执行-它要求如果一个分支创建了在下游使用的张量，则另一个分支也必须创建该张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `then` branch\n",
      "Tracing `else` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=747, shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "    x = tf.constant(0)\n",
    "    if tf.constant(True):\n",
    "        x = x + 1\n",
    "        print(\"Tracing `then` branch\")\n",
    "    else:\n",
    "        x = x - 1\n",
    "        print(\"Tracing `else` branch\")\n",
    "    return x\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-25-810946e9b87f>:3 f  *\n",
      "        if tf.constant(True):\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:893 if_stmt\n",
      "        basic_symbol_names, composite_symbol_names)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:931 tf_if_stmt\n",
      "        error_checking_orelse)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py:507 new_func\n",
      "        return func(*args, **kwargs)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py:1174 cond\n",
      "        return cond_v2.cond_v2(pred, true_fn, false_fn, name)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py:91 cond_v2\n",
      "        op_return_value=pred)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:915 func_graph_from_py_func\n",
      "        func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:924 error_checking_orelse\n",
      "        result[orelse_branch] = orelse()\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:962 wrapper\n",
      "        new_vars = func()\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:988 wrapper\n",
      "        tuple(s.symbol_name for s in undefined)))\n",
      "\n",
      "    ValueError: The following symbols must also be initialized in the else branch: ('x',). Alternatively, you may initialize them before the if statement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "    if tf.constant(True):\n",
    "        x = tf.ones([3, 3])\n",
    "    return x\n",
    "\n",
    "# Throws an error because both branches need to define `x`.\n",
    "with assert_raises(ValueError):\n",
    "    f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph和循环<br>\n",
    "AutoGraph具有一些用于转换循环的简单规则。\n",
    "\n",
    "* for：如果iterable是张量，则转换\n",
    "* while：如果while条件取决于张量，则进行转换\n",
    "\n",
    "如果转换了一个循环，它将动态转换为tf.while_loop，或者在特殊情况下（a for x in tf.data.Dataset）转换为tf.data.Dataset.reduce。\n",
    "\n",
    "如果循环未转换，它将被静态展开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dynamically_unrolled(f, *args):\n",
    "    g = f.get_concrete_function(*args).graph\n",
    "    if any(node.name == 'while' for node in g.as_graph_def().node):\n",
    "        print(\"{}({}) uses tf.while_loop.\".format(\n",
    "            f.__name__, ', '.join(map(str, args))))\n",
    "    elif any(node.name == 'ReduceDataset' for node in g.as_graph_def().node):\n",
    "        print(\"{}({}) uses tf.data.Dataset.reduce.\".format(\n",
    "            f.__name__, ', '.join(map(str, args))))\n",
    "    else:\n",
    "        print(\"{}({}) gets unrolled.\".format(\n",
    "            f.__name__, ', '.join(map(str, args))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_range() gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def for_in_range():\n",
    "    x = 0\n",
    "    for i in range(5):\n",
    "        x += i\n",
    "    return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_tfrange() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def for_in_tfrange():\n",
    "    x = tf.constant(0, dtype=tf.int32)\n",
    "    for i in tf.range(5):\n",
    "        x += i\n",
    "    return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_tfrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_tfdataset() uses tf.data.Dataset.reduce.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def for_in_tfdataset():\n",
    "    x = tf.constant(0, dtype=tf.int64)\n",
    "    for i in tf.data.Dataset.range(5):\n",
    "        x += i\n",
    "    return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_tfdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_py_cond() gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_py_cond():\n",
    "    x = 5\n",
    "    while x > 0:\n",
    "        x -= 1\n",
    "    return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_tf_cond() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_tf_cond():\n",
    "    x = tf.constant(5)\n",
    "    while x > 0:\n",
    "        x -= 1\n",
    "    return x\n",
    "\n",
    "\n",
    "test_dynamically_unrolled(while_tf_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您有一个break或一个return取决于张量的早期子句，则顶级条件或可迭代值也应为张量。\n",
    "\n",
    "比较以下示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_py_true_py_break(5) gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_py_true_py_break(x):\n",
    "    while True:  # py true\n",
    "        if x == 0: # py break\n",
    "            break\n",
    "        x -= 1\n",
    "    return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_true_py_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'TypeError'>: in converted code:\n",
      "\n",
      "    <ipython-input-34-148e37f3ea71>:3 buggy_while_py_true_tf_break  *\n",
      "        while True:   # py true\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:730 while_stmt\n",
      "        return _py_while_stmt(test, body, get_state, set_state, init_vars, opts)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:845 _py_while_stmt\n",
      "        while test(*loop_vars):\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:765 __bool__\n",
      "        self._disallow_bool_casting()\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:531 _disallow_bool_casting\n",
      "        \"using a `tf.Tensor` as a Python `bool`\")\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:518 _disallow_when_autograph_enabled\n",
      "        \" decorating it directly with @tf.function.\".format(task))\n",
      "\n",
      "    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_while_py_true_tf_break(x):\n",
    "    while True:   # py true\n",
    "        if tf.equal(x, 0): # tf break\n",
    "            break\n",
    "        x -= 1\n",
    "    return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "    test_dynamically_unrolled(buggy_while_py_true_tf_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_tf_true_tf_break(5) uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_tf_true_tf_break(x):\n",
    "    while tf.constant(True): # tf true\n",
    "        if x == 0:  # py break\n",
    "            break\n",
    "        x -= 1\n",
    "    return x\n",
    "\n",
    "test_dynamically_unrolled(while_tf_true_tf_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'TypeError'>: in converted code:\n",
      "\n",
      "    <ipython-input-36-b5619b3e6d52>:4 buggy_py_for_tf_break  *\n",
      "        for i in range(5):  # py for\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:339 for_stmt\n",
      "        return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:348 _py_for_stmt\n",
      "        if extra_test is not None and not extra_test(*state):\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:765 __bool__\n",
      "        self._disallow_bool_casting()\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:531 _disallow_bool_casting\n",
      "        \"using a `tf.Tensor` as a Python `bool`\")\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:518 _disallow_when_autograph_enabled\n",
      "        \" decorating it directly with @tf.function.\".format(task))\n",
      "\n",
      "    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_py_for_tf_break():\n",
    "    x = 0\n",
    "    for i in range(5):  # py for\n",
    "        if tf.equal(i, 3): # tf break\n",
    "            break\n",
    "        x += i\n",
    "    return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "    test_dynamically_unrolled(buggy_py_for_tf_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_for_py_break() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def tf_for_py_break():\n",
    "    x = 0\n",
    "    for i in tf.range(5): # tf for\n",
    "        if i == 3:  # py break\n",
    "            break\n",
    "        x += i\n",
    "    return x\n",
    "\n",
    "test_dynamically_unrolled(tf_for_py_break)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了累积来自动态展开循环的结果，您需要使用tf.TensorArray。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1254, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.35653508, 0.01149547, 0.9093461 , 0.5242202 ],\n",
       "        [0.39132583, 0.92087126, 1.0783565 , 0.8690239 ],\n",
       "        [0.78924966, 1.7890056 , 1.484895  , 1.1597422 ]],\n",
       "\n",
       "       [[0.55073607, 0.6544552 , 0.74741924, 0.5474757 ],\n",
       "        [0.6120492 , 1.6240565 , 1.2154746 , 0.8164532 ],\n",
       "        [0.6337079 , 1.8681042 , 1.2629682 , 1.5568563 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "    return inp + state\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "  # [batch, time, features] -> [time, batch, features]\n",
    "    input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "    max_seq_len = input_data.shape[0]\n",
    "\n",
    "    states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "    state = initial_state\n",
    "    for i in tf.range(max_seq_len):\n",
    "        state = rnn_step(input_data[i], state)\n",
    "        states = states.write(i, state)\n",
    "    return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "dynamic_rnn(rnn_step,\n",
    "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与一样tf.cond，tf.while_loop还带有一些微妙之处。-由于循环可执行0次，因此必须在循环上方初始化while_loop下游使用的所有张量-所有循环变量的shape / dtype必须与每次迭代保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-39-fb9c665fb220>:3 buggy_loop_var_uninitialized  *\n",
      "        for i in tf.range(3):\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:315 for_stmt\n",
      "        composite_symbol_names)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:419 _tf_range_for_stmt\n",
      "        _disallow_undefs_into_loop(*init_vars)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:97 _disallow_undefs_into_loop\n",
      "        ' before the loop: {}'.format(tuple(s.symbol_name for s in undefined)))\n",
      "\n",
      "    ValueError: TensorFlow requires that the following symbols must be defined before the loop: ('x',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_loop_var_uninitialized():\n",
    "    for i in tf.range(3):\n",
    "        x = i\n",
    "    return x\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "    buggy_loop_var_uninitialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1309, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "    x = tf.constant(0)\n",
    "    for i in tf.range(3):\n",
    "        x = i\n",
    "    return x\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got unexpected exception \n",
      "  <class 'TypeError'>: in converted code:\n",
      "\n",
      "    <ipython-input-41-f464a413782d>:4 buggy_loop_type_changes  *\n",
      "        for i in tf.range(3): # Yields tensors of type tf.int32...\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:315 for_stmt\n",
      "        composite_symbol_names)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:478 _tf_range_for_stmt\n",
      "        opts=opts,\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:769 _tf_while_stmt\n",
      "        aug_init_vars, **opts)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py:2675 while_loop\n",
      "        back_prop=back_prop)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:198 while_loop\n",
      "        add_control_dependencies=add_control_dependencies)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:915 func_graph_from_py_func\n",
      "        func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:176 wrapped_body\n",
      "        outputs = body(*_pack_sequence_as(orig_loop_vars, args))\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:759 aug_body\n",
      "        composite_symbol_names)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:195 _verify_tf_loop_vars\n",
      "        first_iter_var)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py:535 map_structure\n",
      "        structure[0], [func(*x) for x in entries],\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py:535 <listcomp>\n",
      "        structure[0], [func(*x) for x in entries],\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:179 _check_same_type\n",
      "        first_iter_var.dtype.name,\n",
      "\n",
      "    TypeError: \"x\" has dtype float32 before the loop, but dtype int32 after one iteration. TensorFlow control flow requires it stays the same.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_loop_type_changes():\n",
    "    x = tf.constant(0, dtype=tf.float32)\n",
    "    for i in tf.range(3): # Yields tensors of type tf.int32...\n",
    "        x = i\n",
    "    return x\n",
    "\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "    buggy_loop_type_changes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-42-df6f2beb378a>:4 buggy_concat  *\n",
      "        for i in tf.range(5):\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:315 for_stmt\n",
      "        composite_symbol_names)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:478 _tf_range_for_stmt\n",
      "        opts=opts,\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:769 _tf_while_stmt\n",
      "        aug_init_vars, **opts)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py:2675 while_loop\n",
      "        back_prop=back_prop)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:198 while_loop\n",
      "        add_control_dependencies=add_control_dependencies)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:915 func_graph_from_py_func\n",
      "        func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:176 wrapped_body\n",
      "        outputs = body(*_pack_sequence_as(orig_loop_vars, args))\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:759 aug_body\n",
      "        composite_symbol_names)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:195 _verify_tf_loop_vars\n",
      "        first_iter_var)\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py:535 map_structure\n",
      "        structure[0], [func(*x) for x in entries],\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py:535 <listcomp>\n",
      "        structure[0], [func(*x) for x in entries],\n",
      "    c:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\control_flow.py:191 _check_same_type\n",
      "        first_iter_shape))\n",
      "\n",
      "    ValueError: \"x\" has shape (0, 10) before the loop, but shape (1, 10) after one iteration. TensorFlow control flow requires it stays the same or be more specific.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_concat():\n",
    "    x = tf.ones([0, 10])\n",
    "    for i in tf.range(5):\n",
    "        x = tf.concat([x, tf.ones([1, 10])], axis=0)\n",
    "    return x\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "    buggy_concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1432, shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def concat_with_padding():\n",
    "    x = tf.zeros([5, 10])\n",
    "    for i in tf.range(5):\n",
    "        x = tf.concat([x[:i], tf.ones([1, 10]), tf.zeros([4-i, 10])], axis=0)\n",
    "        x.set_shape([5, 10])\n",
    "    return x\n",
    "\n",
    "concat_with_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
