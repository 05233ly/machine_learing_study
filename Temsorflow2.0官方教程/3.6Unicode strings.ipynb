{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍\n",
    "\n",
    "处理自然语言的模型通常使用不同的字符集来处理不同的语言。 Unicode是一种标准的编码系统，用于表示几乎所有语言的字符。每个字符使用和之间的唯一整数代码点编码。甲Unicode字符串是零个或更多个码点的序列。00x10FFFF\n",
    "\n",
    "本教程介绍了如何在TensorFlow中表示Unicode字符串，以及如何使用与标准字符串ops等效的Unicode进行操作。它将基于脚本检测将Unicode字符串分成令牌。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、默认的tensorflow字符串常量默认为utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该tf.string数据类型\n",
    "\n",
    "基本的TensorFlow 允许您构建字节串的张量。Unicode字符串默认为utf-8编码。tf.string dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"Thanks 😊\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个tf.string张量可容纳不同长度的字节串，因为字节串作为原子单位处理。张量尺寸中不包括字符串长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、不同的编码格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表示Unicode\n",
    "在TensorFlow中有两种表示Unicode字符串的标准方法：\n",
    "\n",
    "* string标量—使用已知的字符编码对代码点序列进行编码。\n",
    "* int32 向量-每个位置都包含一个代码点。\n",
    "\n",
    "例如，以下三个值均表示Unicode字符串\"语言处理\"（在中文中表示“语言处理”）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(u\"语言处理\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"语言处理\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a vector of Unicode code points.\n",
    "text_chars = tf.constant([ord(char) for char in u\"语言处理\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、不同编码格式之间的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在制图表达之间转换\n",
    "TensorFlow提供了在这些不同表示之间进行转换的操作：\n",
    "\n",
    "* tf.strings.unicode_decode：将编码的字符串标量转换为代码点的向量。\n",
    "* tf.strings.unicode_encode：将代码点的向量转换为编码的字符串标量。\n",
    "* tf.strings.unicode_transcode：将编码的字符串标量转换为其他编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8,\n",
    "                          input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars,\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=19, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8,\n",
    "                             input_encoding='UTF8',\n",
    "                             output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、按批次编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批次尺寸\n",
    "\n",
    "解码多个字符串时，每个字符串中的字符数可能不相等。返回结果是a tf.RaggedTensor，其中最里面的维的长度根据每个字符串中的字符数而变化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "              [u'hÃllo',  u'What is the weather tomorrow',  u'Göödnight', u'😊']]\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "    print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以tf.RaggedTensor直接使用此格式，也可以使用tf.Tensorpadding或tf.SparseTensor使用方法tf.RaggedTensor.to_tensor和将其转换为密集格式tf.RaggedTensor.to_sparse。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定长填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28)\n"
     ]
    }
   ],
   "source": [
    "print(batch_chars_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 1  0]\n",
      " [ 1  1]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 1  4]\n",
      " [ 1  5]\n",
      " [ 1  6]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 13]\n",
      " [ 1 14]\n",
      " [ 1 15]\n",
      " [ 1 16]\n",
      " [ 1 17]\n",
      " [ 1 18]\n",
      " [ 1 19]\n",
      " [ 1 20]\n",
      " [ 1 21]\n",
      " [ 1 22]\n",
      " [ 1 23]\n",
      " [ 1 24]\n",
      " [ 1 25]\n",
      " [ 1 26]\n",
      " [ 1 27]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 2  3]\n",
      " [ 2  4]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2  7]\n",
      " [ 2  8]\n",
      " [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n",
      "[   104    195    108    108    111     87    104     97    116     32\n",
      "    105    115     32    116    104    101     32    119    101     97\n",
      "    116    104    101    114     32    116    111    109    111    114\n",
      "    114    111    119     71    246    246    100    110    105    103\n",
      "    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "print(batch_chars_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28)\n"
     ]
    }
   ],
   "source": [
    "print(batch_chars_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、解码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在对多个具有相同长度的字符串进行编码时，可以将一个tf.Tensor用作输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=119, shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对长度可变的多个字符串进行编码时，应将一个tf.RaggedTensor用作输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=120, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您的张量具有填充或稀疏格式的多个字符串，请tf.RaggedTensor在调用之前将其转换为unicode_encode："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=199, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=272, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、长度相关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicode操作\n",
    "\n",
    "字符长度\n",
    "\n",
    "该tf.strings.length操作具有一个参数unit，该参数指示应如何计算长度。 unit默认为\"BYTE\"，但是可以将其设置为其他值，例如\"UTF8_CHAR\"或\"UTF16_CHAR\"，以确定每个已编码的Unicode代码点的数量string。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; 8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# Note that the final character takes up 4 bytes in UTF8.\n",
    "thanks = u'Thanks 😊'.encode('UTF-8')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字符子串\n",
    "\n",
    "类似地，该tf.strings.substr操作接受“ unit”参数，并使用它来确定“ pos”和“ len”参数包含的偏移量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: unit='BYTE'. With len=1, we return a single byte.\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xf0\\x9f\\x98\\x8a'\n"
     ]
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', we return a single character, which in this case\n",
    "# is 4 bytes.\n",
    "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拆分Unicode字符串\n",
    "\n",
    "该tf.strings.unicode_split操作将unicode字符串拆分为各个字符的子字符串："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、字符的字节偏移\n",
    "\n",
    "为了将生成的字符张量tf.strings.unicode_decode与原始字符串对齐，了解每个字符开始位置的偏移量很有用。该方法tf.strings.unicode_decode_with_offsets类似于unicode_decode，除了它返回包含每个字符的起始偏移量的第二张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint 127880\n",
      "At byte offset 4: codepoint 127881\n",
      "At byte offset 8: codepoint 127882\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"🎈🎉🎊\", 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "    print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8、获取编码使用哪个脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicode脚本\n",
    "\n",
    "每个Unicode代码点都属于一个称为脚本的代码点的单个集合。角色的脚本有助于确定角色可能使用的语言。例如，知道西里尔字母中的'Б'表示该包含该角色的现代文本很可能来自斯拉夫语，例如俄语或乌克兰语。\n",
    "\n",
    "TensorFlow提供了tf.strings.unicode_script确定给定代码点使用哪个脚本的操作。脚本代码是int32与Unicode国际组件（ICU）UScriptCode值相对应的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['芸', 'Б']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：简单细分\n",
    "\n",
    "分段是将文本拆分为类似单词的单元的任务。当使用空格字符分隔单词时，这通常很容易，但是某些语言（如中文和日语）不使用空格，而某些语言（如德语）包含必须分解以分析其含义的长化合物。在Web文本中，经常将不同的语言和脚本混合在一起，例如“ NY株価”（纽约证券交易所）。\n",
    "\n",
    "通过使用脚本中的更改来近似单词边界，我们可以执行非常粗略的细分（无需实现任何ML模型）。这将适用于上面的“ NY株価”示例之类的字符串。它也适用于大多数使用空格的语言，因为各种脚本的空格字符都归类为USCRIPT_COMMON，这是一种特殊的脚本代码，不同于任何实际的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "#\n",
    "# The sentences to process.  Edit this line to try out different inputs!\n",
    "sentence_texts = [u'Hello, world.', u'世界こんにちは']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们将句子解码为字符代码点，然后为每个字符找到脚本标识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] is the codepoint for the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_scripts[i, j] is the unicode script of the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9、根据脚本标识确认单词边界的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们使用这些脚本标识符来确定应在何处添加单词边界。我们在每个句子的开头以及脚本与上一个字符不同的每个字符处添加单词边界："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算不一样的边界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n",
    "# sentence is the start of a word.\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] is the index of the character that starts the i'th word (in\n",
    "# the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们可以使用这些起始偏移量来构建一个RaggedTensor包含所有批次的单词列表的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
    "# i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_char_codepoint.values,\n",
    "    row_starts=word_starts)\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们可以将代码点这个词细分RaggedTensor为句子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转回"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了使最终结果更易于阅读，我们可以将其编码回UTF-8字符串："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hello', b', ', b'world', b'.'],\n",
       " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
       "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
