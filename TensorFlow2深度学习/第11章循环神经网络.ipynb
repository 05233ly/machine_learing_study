{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "x = tf.range(10)\n",
    "x = tf.random.shuffle(x)\n",
    "# 创建共10个单词，每个单词用长度为4的向量表示的层\n",
    "net = layers.Embedding(10, 4)\n",
    "out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[ 0.7576244 ,  0.87684464, -0.18167937],\n",
       "        [-0.24517381, -0.0435093 , -0.7579328 ],\n",
       "        [ 0.7295934 ,  0.05551606,  0.0779804 ],\n",
       "        [ 0.50561786,  0.38797855, -0.09666789]], dtype=float32)>,\n",
       " <tf.Variable 'recurrent_kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[-0.36170995, -0.9119809 ,  0.19353722],\n",
       "        [ 0.8348372 , -0.22443914,  0.50266683],\n",
       "        [-0.41498524,  0.34339172,  0.84253746]], dtype=float32)>,\n",
       " <tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = layers.SimpleRNNCell(3)\n",
    "cell.build(input_shape=(None,4))\n",
    "cell.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 64) (4, 64)\n",
      "3033784686968 3033784686968\n"
     ]
    }
   ],
   "source": [
    "h0 = [tf.zeros([4, 64])]\n",
    "x = tf.random.normal([4, 80, 100])\n",
    "xt = x[:,0,:]\n",
    "# 构建输入特征f=100,序列长度s=80,状态长度=64的Cell\n",
    "cell = layers.SimpleRNNCell(64)\n",
    "out, h1 = cell(xt, h0) # 前向计算\n",
    "print(out.shape, h1[0].shape)\n",
    "print(id(out), id(h1[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "h = h0\n",
    "# i=0\n",
    "# 在序列长度的维度解开输入，得到xt:[b,f]\n",
    "for xt in tf.unstack(x, axis=1):\n",
    "    out, h = cell(xt, h) # 前向计算\n",
    "#     print(i)\n",
    "#     i=i+1\n",
    "# 最终输出可以聚合每个时间戳上的输出，也可以只取最后时间戳的输出\n",
    "out = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 100)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "x = tf.random.normal([4,80,100])\n",
    "xt = x[:,0,:] # 取第一个时间戳的输入x0\n",
    "print(xt.shape)\n",
    "# 构建2个Cell,先cell0,后cell1\n",
    "cell0 = layers.SimpleRNNCell(64)\n",
    "cell1 = layers.SimpleRNNCell(64)\n",
    "h0 = [tf.zeros([4,64])] # cell0的初始状态向量\n",
    "h1 = [tf.zeros([4,64])] # cell1的初始状态向量\n",
    "\n",
    "out0, h0 = cell0(xt, h0)\n",
    "out1, h1 = cell1(out0, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "for xt in tf.unstack(x, axis=1):\n",
    "#     print(xt.shape)\n",
    "    # xtw作为输入，输出为out0\n",
    "    out0, h0 = cell0(xt, h0)\n",
    "    # 上一个cell的输出out0作为本cell的输入\n",
    "    out1, h1 = cell1(out0, h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 80, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "# 保存上一层的所有时间戳上面的输出\n",
    "middle_sequences = []\n",
    "# 计算第一层的所有时间戳上的输出，并保存\n",
    "for xt in tf.unstack(x, axis=1):\n",
    "    out0, h0 = cell0(xt, h0)\n",
    "    middle_sequences.append(out0)\n",
    "# 计算第二层的所有时间戳上的输出\n",
    "# 如果不是末层，需要保存所有时间戳上面的输出\n",
    "for xt in middle_sequences:\n",
    "    out1, h1 = cell1(xt, h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleRNN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.SimpleRNN(64)\n",
    "x = tf.random.normal([4, 80, 100])\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 80, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.SimpleRNN(64,return_sequences=True)\n",
    "out = layer(x) \n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = keras.Sequential([ # 构建2层RNN网络\n",
    "# 除最末层外，都需要返回所有时间戳的输出\n",
    "layers.SimpleRNN(64, return_sequences=True),\n",
    "layers.SimpleRNN(64),\n",
    "])\n",
    "out = net(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN情感分析实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers, losses, optimizers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) 218 (25000,)\n",
      "(25000,) 68 (25000,)\n"
     ]
    }
   ],
   "source": [
    "batchsz = 512 # 批量大小\n",
    "total_words = 10000 # 词汇表大小N_vocab\n",
    "max_review_len = 80 # 句子最大长度s，大于的句子部分将截断，小于的将填充\n",
    "embedding_len = 100 # 词向量特征长度f\n",
    "# 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n",
    "print(x_train.shape, len(x_train[0]), y_train.shape)\n",
    "print(x_test.shape, len(x_test[0]), y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字编码表\n",
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in word_index.items():\n",
    "#     print(k,v)\n",
    "#%%\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "# 翻转编码表\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88588"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> just got out and cannot believe what a brilliant documentary this is rarely do you walk out of a movie theater in such awe and <UNK> lately movies have become so over hyped that the thrill of discovering something truly special and unique rarely happens <UNK> <UNK> did this to me when it first came out and this movie is doing to me now i didn't know a thing about this before going into it and what a surprise if you hear the concept you might get the feeling that this is one of those <UNK> movies about an amazing triumph covered with over the top music and trying to have us fully convinced of what a great story it is telling but then not letting us in <UNK> this is not that movie the people tell the story this does such a good job of capturing every moment of their involvement while we enter their world and feel every second with them there is so much beyond the climb that makes everything they go through so much more tense touching the void was also a great doc about mountain climbing and showing the intensity in an engaging way but this film is much more of a human story i just saw it today but i will go and say that this is one of the best documentaries i have ever seen\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(x_train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "# x_train:[b, 80]\n",
    "# x_test: [b, 80]\n",
    "# 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
    "print('x_train shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(keras.Model):\n",
    "    # Cell方式构建多层网络\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__() \n",
    "        # 词向量编码 [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # 构建RNN\n",
    "        self.rnn = keras.Sequential([\n",
    "            layers.SimpleRNN(units, dropout=0.5, return_sequences=True),\n",
    "            layers.SimpleRNN(units, dropout=0.5)\n",
    "        ])\n",
    "        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "            layers.Dense(32),\n",
    "            layers.Dropout(rate=0.5),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(1)])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [b, 80]\n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        x = self.rnn(x)\n",
    "        # 末层最后一个输出作为分类网络的输入: [b, 64] => [b, 1]\n",
    "        x = self.outlayer(x,training)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64 # RNN状态向量长度f\n",
    "epochs = 50 # 训练epochs\n",
    "\n",
    "model = MyRNN(units)\n",
    "# 装配\n",
    "model.compile(optimizer = optimizers.Adam(0.001),\n",
    "              loss = losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "48/48 [==============================] - 7s 144ms/step - loss: 0.7100 - accuracy: 0.5012 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 5s 106ms/step - loss: 0.6938 - accuracy: 0.5068 - val_loss: 0.6921 - val_accuracy: 0.5366\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 5s 105ms/step - loss: 0.6858 - accuracy: 0.5490 - val_loss: 0.6220 - val_accuracy: 0.6859\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 5s 105ms/step - loss: 0.5172 - accuracy: 0.7587 - val_loss: 0.3893 - val_accuracy: 0.8270\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 5s 105ms/step - loss: 0.3619 - accuracy: 0.8537 - val_loss: 0.4350 - val_accuracy: 0.8291\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 5s 106ms/step - loss: 0.2958 - accuracy: 0.8867 - val_loss: 0.4873 - val_accuracy: 0.8255\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.2324 - accuracy: 0.9142 - val_loss: 0.4908 - val_accuracy: 0.8276\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.1761 - accuracy: 0.9367 - val_loss: 0.5736 - val_accuracy: 0.8206\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.1402 - accuracy: 0.9511 - val_loss: 0.6763 - val_accuracy: 0.8118\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.1028 - accuracy: 0.9655 - val_loss: 0.7878 - val_accuracy: 0.8154\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 0.0856 - accuracy: 0.9709 - val_loss: 0.8154 - val_accuracy: 0.8199\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0680 - accuracy: 0.9768 - val_loss: 0.8636 - val_accuracy: 0.8200\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0642 - accuracy: 0.9773 - val_loss: 0.9730 - val_accuracy: 0.8202\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0613 - accuracy: 0.9795 - val_loss: 0.9158 - val_accuracy: 0.8178\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.9723 - val_accuracy: 0.8191\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 0.9233 - val_accuracy: 0.8143\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 1.0627 - val_accuracy: 0.8171\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 1.2337 - val_accuracy: 0.8116\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 1.0310 - val_accuracy: 0.8108\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 1.0957 - val_accuracy: 0.8204\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 1.2245 - val_accuracy: 0.8184\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 1.1351 - val_accuracy: 0.8173\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 5s 111ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 1.0483 - val_accuracy: 0.7873\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 5s 106ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 1.1349 - val_accuracy: 0.8137\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 1.2336 - val_accuracy: 0.8095\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 1.1594 - val_accuracy: 0.8105\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 1.2103 - val_accuracy: 0.8178\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 5s 106ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 1.1249 - val_accuracy: 0.8064\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 5s 106ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 1.1395 - val_accuracy: 0.8084\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 1.1502 - val_accuracy: 0.8120\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 1.3304 - val_accuracy: 0.8054\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 1.1945 - val_accuracy: 0.8121\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 1.1770 - val_accuracy: 0.8125\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 1.2394 - val_accuracy: 0.8142\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 1.2096 - val_accuracy: 0.8050\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 1.1673 - val_accuracy: 0.8079\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 5s 105ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 1.2480 - val_accuracy: 0.8132\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 1.3945 - val_accuracy: 0.8127\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 5s 106ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 1.3452 - val_accuracy: 0.8186\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 1.4230 - val_accuracy: 0.8151\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.3935 - val_accuracy: 0.8129\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 1.4523 - val_accuracy: 0.8165\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.4791 - val_accuracy: 0.8157\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 1.5166 - val_accuracy: 0.8094\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 1.2850 - val_accuracy: 0.8086\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 1.3556 - val_accuracy: 0.8138\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 1.5272 - val_accuracy: 0.8139\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 1.3368 - val_accuracy: 0.8145\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 1.3906 - val_accuracy: 0.8099\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 5s 107ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 1.4069 - val_accuracy: 0.8151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab97ba3e10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练和验证\n",
    "model.fit(db_train, epochs=epochs, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 17ms/step - loss: 1.4069 - accuracy: 0.8151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.406923530002435, 0.81514484]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度弥散和梯度爆炸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30927, shape=(2,), dtype=float32, numpy=array([0., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = tf.ones([2,2]) # 任意创建某矩阵\n",
    "eigenvalues = tf.linalg.eigh(W)[0] # 计算特征值\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%\n",
    "val = [W]\n",
    "for i in range(10): # 矩阵相乘n次方\n",
    "    val.append([val[-1]@W])\n",
    "# 计算L2范数\n",
    "norm = list(map(lambda x:tf.norm(x).numpy(),val))\n",
    "plt.plot(range(1,12),norm)\n",
    "plt.xlabel('n times')\n",
    "plt.ylabel('L2-norm')\n",
    "# plt.savefig('w_n_times_1.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.  0.8], shape=(2,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%\n",
    "W = tf.ones([2,2])*0.4 # 任意创建某矩阵\n",
    "eigenvalues = tf.linalg.eigh(W)[0] # 计算特征值\n",
    "print(eigenvalues)\n",
    "val = [W]\n",
    "for i in range(10):\n",
    "    val.append([val[-1]@W])\n",
    "norm = list(map(lambda x:tf.norm(x).numpy(),val))\n",
    "plt.plot(range(1,12),norm)\n",
    "plt.xlabel('n times')\n",
    "plt.ylabel('L2-norm')\n",
    "# plt.savefig('w_n_times_0.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=31114, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.4       , 0.59142506],\n",
       "       [0.6       , 0.6       ]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "a=tf.random.uniform([2,2])\n",
    "tf.clip_by_value(a,0.4,0.6) # 梯度值裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=31145, shape=(), dtype=float32, numpy=8.08476>,\n",
       " <tf.Tensor: id=31150, shape=(), dtype=float32, numpy=4.9999995>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.random.uniform([2,2]) * 5\n",
    "# 按范数方式裁剪\n",
    "b = tf.clip_by_norm(a, 5)\n",
    "tf.norm(a),tf.norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.2026575, shape=(), dtype=float32) tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w1=tf.random.normal([3,3]) # 创建梯度张量1\n",
    "w2=tf.random.normal([3,3]) # 创建梯度张量2\n",
    "# 计算global norm\n",
    "global_norm=tf.math.sqrt(tf.norm(w1)**2+tf.norm(w2)**2) \n",
    "# 根据global norm和max norm=2裁剪\n",
    "(ww1,ww2),global_norm=tf.clip_by_global_norm([w1,w2],2)\n",
    "# 计算裁剪后的张量组的global norm\n",
    "global_norm2 = tf.math.sqrt(tf.norm(ww1)**2+tf.norm(ww2)**2)\n",
    "print(global_norm, global_norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    logits = model(x) # 前向传播\n",
    "    loss = criteon(y, logits) # 误差计算\n",
    "# 计算梯度值\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "grads, _ = tf.clip_by_global_norm(grads, 25) # 全局梯度裁剪\n",
    "# 利用裁剪后的梯度张量更新参数\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1836571435080, 1836571435080, 1836569425456)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([2,80,100])\n",
    "xt = x[:,0,:] # 得到一个时间戳的输入\n",
    "cell = layers.LSTMCell(64) # 创建Cell\n",
    "# 初始化状态和输出List,[h,c]\n",
    "state = [tf.zeros([2,64]),tf.zeros([2,64])]\n",
    "out, state = cell(xt, state) # 前向计算\n",
    "id(out),id(state[0]),id(state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'kernel:0' shape=(3, 16) dtype=float32, numpy=\n",
       " array([[ 0.11973578,  0.03518277, -0.47716   ,  0.52556413, -0.0078398 ,\n",
       "          0.20304042, -0.3032422 ,  0.55840546,  0.15683568,  0.510279  ,\n",
       "          0.44711846, -0.21903077,  0.12290078,  0.54183084, -0.4215247 ,\n",
       "         -0.00953424],\n",
       "        [ 0.42180926,  0.3431865 , -0.06528306, -0.02494115,  0.0208171 ,\n",
       "          0.1292929 , -0.09635094, -0.4720353 ,  0.12636602, -0.09750342,\n",
       "          0.3340153 , -0.15362537,  0.40015268,  0.29057842, -0.06269979,\n",
       "          0.08761692],\n",
       "        [ 0.5431548 , -0.35553515, -0.47243896,  0.5494618 ,  0.5150735 ,\n",
       "          0.3364609 ,  0.12205857, -0.37847757,  0.4122151 , -0.21188161,\n",
       "          0.22288239,  0.54009086,  0.4181701 ,  0.3864168 ,  0.37283474,\n",
       "          0.02733451]], dtype=float32)>,\n",
       " <tf.Variable 'recurrent_kernel:0' shape=(4, 16) dtype=float32, numpy=\n",
       " array([[-0.24952722, -0.10625644, -0.09382117, -0.10740637, -0.00578529,\n",
       "         -0.21587995, -0.28717503, -0.37882805,  0.1831666 , -0.07238756,\n",
       "         -0.27933535,  0.20882131,  0.55662704, -0.3248466 , -0.07971117,\n",
       "          0.22660956],\n",
       "        [-0.22731578,  0.03481632,  0.00233931,  0.1511055 , -0.09505951,\n",
       "         -0.0363612 ,  0.04866216,  0.02701611, -0.23592822,  0.22070035,\n",
       "         -0.33036262, -0.05263192,  0.00289673, -0.38281167,  0.01394427,\n",
       "         -0.7401301 ],\n",
       "        [ 0.11974192,  0.41868532, -0.1649645 ,  0.10041971, -0.335924  ,\n",
       "         -0.30799806,  0.17687619, -0.1585762 , -0.25144613,  0.2943356 ,\n",
       "         -0.25853342, -0.31481126,  0.06651956,  0.20321155, -0.28007993,\n",
       "          0.26260048],\n",
       "        [-0.4101219 , -0.4314191 ,  0.0322246 , -0.06685387,  0.03725604,\n",
       "         -0.4210332 ,  0.02083345,  0.11911134,  0.0453071 , -0.12959853,\n",
       "         -0.07443255, -0.01558404, -0.26409006,  0.3143381 , -0.49761602,\n",
       "         -0.07801104]], dtype=float32)>,\n",
       " <tf.Variable 'bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = layers.LSTM(4)\n",
    "net.build(input_shape=(None,5,3))\n",
    "net.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'kernel:0' shape=(3, 12) dtype=float32, numpy=\n",
       " array([[ 0.40103143, -0.46793008,  0.3814847 ,  0.51146156,  0.3826415 ,\n",
       "          0.3651896 , -0.6017788 ,  0.3965158 , -0.19388166,  0.03471923,\n",
       "         -0.51278925, -0.1108647 ],\n",
       "        [ 0.02897578, -0.47327948, -0.50863713, -0.4810816 ,  0.1730637 ,\n",
       "         -0.12884796,  0.34725022,  0.27582896, -0.33340415, -0.07083064,\n",
       "          0.46814185,  0.6200231 ],\n",
       "        [-0.22236815, -0.04058945,  0.46621603, -0.6206591 , -0.34952667,\n",
       "          0.19986922, -0.12645131,  0.4276741 , -0.23295566, -0.5026454 ,\n",
       "         -0.2553554 , -0.16029504]], dtype=float32)>,\n",
       " <tf.Variable 'recurrent_kernel:0' shape=(4, 12) dtype=float32, numpy=\n",
       " array([[ 0.37123013,  0.03152082, -0.37531132,  0.25066817,  0.24339297,\n",
       "          0.3495937 , -0.00814347, -0.06495688,  0.3055531 , -0.27549997,\n",
       "          0.23408014,  0.49769822],\n",
       "        [-0.2818142 ,  0.45015973, -0.01958858,  0.59077823,  0.03106868,\n",
       "         -0.30167732, -0.22660333,  0.404171  , -0.08966576,  0.09036084,\n",
       "          0.15459627,  0.14748394],\n",
       "        [ 0.29476497,  0.28125638,  0.1888462 , -0.25677034,  0.35446623,\n",
       "          0.01198415,  0.07493002,  0.5079924 ,  0.05434219, -0.08093806,\n",
       "         -0.5671831 ,  0.10841163],\n",
       "        [ 0.47321117,  0.14045438, -0.09842379,  0.03355395,  0.16755381,\n",
       "         -0.66638064, -0.16861595, -0.32769516,  0.23620257, -0.03386554,\n",
       "          0.0157457 , -0.28353372]], dtype=float32)>,\n",
       " <tf.Variable 'bias:0' shape=(2, 12) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = layers.GRU(4)\n",
    "net.build(input_shape=(None,5,3))\n",
    "net.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM文本情感实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(keras.Model):\n",
    "    # Cell方式构建多层网络\n",
    "    def __init__(self, units):\n",
    "        super(MyLSTM, self).__init__() \n",
    "        # 词向量编码 [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # 构建RNN\n",
    "        self.rnn = keras.Sequential([\n",
    "            layers.LSTM(units, dropout=0.5, return_sequences=True),\n",
    "            layers.LSTM(units, dropout=0.5)\n",
    "        ])\n",
    "        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "            layers.Dense(32),\n",
    "            layers.Dropout(rate=0.5),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(1)])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [b, 80]\n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        x = self.rnn(x)\n",
    "        # 末层最后一个输出作为分类网络的输入: [b, 64] => [b, 1]\n",
    "        x = self.outlayer(x,training)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 32 # RNN状态向量长度f\n",
    "epochs = 50 # 训练epochs\n",
    "\n",
    "model = MyLSTM(units)\n",
    "# 装配\n",
    "model.compile(optimizer = optimizers.Adam(0.001),\n",
    "              loss = losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "48/48 [==============================] - 7s 137ms/step - loss: 0.6437 - accuracy: 0.6251 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.4045 - accuracy: 0.8269 - val_loss: 0.3764 - val_accuracy: 0.8317\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.3077 - accuracy: 0.8788 - val_loss: 0.3683 - val_accuracy: 0.8351\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.2627 - accuracy: 0.9001 - val_loss: 0.4351 - val_accuracy: 0.8284\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.2353 - accuracy: 0.9135 - val_loss: 0.4397 - val_accuracy: 0.8291\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.2073 - accuracy: 0.9227 - val_loss: 0.4576 - val_accuracy: 0.8266\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.1936 - accuracy: 0.9282 - val_loss: 0.4996 - val_accuracy: 0.8238\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.1589 - accuracy: 0.9421 - val_loss: 0.5849 - val_accuracy: 0.8188\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.1413 - accuracy: 0.9479 - val_loss: 0.6845 - val_accuracy: 0.8181\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.1262 - accuracy: 0.9538 - val_loss: 0.7217 - val_accuracy: 0.8079\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.1139 - accuracy: 0.9585 - val_loss: 0.7512 - val_accuracy: 0.8134\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0985 - accuracy: 0.9652 - val_loss: 0.7679 - val_accuracy: 0.8130\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0915 - accuracy: 0.9664 - val_loss: 0.7699 - val_accuracy: 0.8114\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0820 - accuracy: 0.9718 - val_loss: 0.9222 - val_accuracy: 0.8094\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0664 - accuracy: 0.9772 - val_loss: 1.0656 - val_accuracy: 0.8081\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0684 - accuracy: 0.9756 - val_loss: 0.9552 - val_accuracy: 0.8084\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0598 - accuracy: 0.9795 - val_loss: 1.0820 - val_accuracy: 0.8030\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0547 - accuracy: 0.9808 - val_loss: 1.0442 - val_accuracy: 0.8092\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0607 - accuracy: 0.9784 - val_loss: 1.0914 - val_accuracy: 0.8085\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0553 - accuracy: 0.9806 - val_loss: 1.0951 - val_accuracy: 0.8058\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 1.1307 - val_accuracy: 0.8098\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0404 - accuracy: 0.9863 - val_loss: 1.1862 - val_accuracy: 0.8086\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 1.2098 - val_accuracy: 0.8087\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 1.3385 - val_accuracy: 0.8037\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0372 - accuracy: 0.9868 - val_loss: 1.1668 - val_accuracy: 0.8090\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 1.1564 - val_accuracy: 0.8094\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 1.3206 - val_accuracy: 0.8046\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 1.4467 - val_accuracy: 0.8074\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0269 - accuracy: 0.9910 - val_loss: 1.4476 - val_accuracy: 0.8061\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 1.5729 - val_accuracy: 0.8029\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 1.7445 - val_accuracy: 0.8066\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 1.6375 - val_accuracy: 0.8075\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 1.7212 - val_accuracy: 0.8063\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 1.6551 - val_accuracy: 0.8064\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 1.5175 - val_accuracy: 0.8062\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 1.3720 - val_accuracy: 0.8068\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 2s 47ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 1.5588 - val_accuracy: 0.8038\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 1.5566 - val_accuracy: 0.8029\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 1.7297 - val_accuracy: 0.8051\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 1.7542 - val_accuracy: 0.8065\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 1.7740 - val_accuracy: 0.8064\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 1.6316 - val_accuracy: 0.8088\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 2s 47ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 1.8703 - val_accuracy: 0.8027\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 2s 47ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 1.6828 - val_accuracy: 0.8053\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 2s 47ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 1.8893 - val_accuracy: 0.8014\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 1.8187 - val_accuracy: 0.8024\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 2s 47ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 1.8299 - val_accuracy: 0.8043\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 2s 47ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 1.6443 - val_accuracy: 0.8031\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 1.5832 - val_accuracy: 0.8053\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 1.5653 - val_accuracy: 0.8026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab9a0c3438>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练和验证\n",
    "model.fit(db_train, epochs=epochs, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5653 - accuracy: 0.8026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5652667904893558, 0.8025716]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU文本情感分析实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGRU(keras.Model):\n",
    "    # Cell方式构建多层网络\n",
    "    def __init__(self, units):\n",
    "        super(MyGRU, self).__init__() \n",
    "        # 词向量编码 [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # 构建RNN\n",
    "        self.rnn = keras.Sequential([\n",
    "            layers.GRU(units, dropout=0.5, return_sequences=True),\n",
    "            layers.GRU(units, dropout=0.5)\n",
    "        ])\n",
    "        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "            layers.Dense(32),\n",
    "            layers.Dropout(rate=0.5),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(1)])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [b, 80]\n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        x = self.rnn(x)\n",
    "        # 末层最后一个输出作为分类网络的输入: [b, 64] => [b, 1]\n",
    "        x = self.outlayer(x,training)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 32 # RNN状态向量长度f\n",
    "epochs = 50 # 训练epochs\n",
    "\n",
    "model = MyGRU(units)\n",
    "# 装配\n",
    "model.compile(optimizer = optimizers.Adam(0.001),\n",
    "              loss = losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 0.6758 - accuracy: 0.5812 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.4593 - accuracy: 0.7940 - val_loss: 0.3759 - val_accuracy: 0.8321\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.3197 - accuracy: 0.8713 - val_loss: 0.3675 - val_accuracy: 0.8428\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.2661 - accuracy: 0.9006 - val_loss: 0.3988 - val_accuracy: 0.8358\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.2385 - accuracy: 0.9095 - val_loss: 0.4050 - val_accuracy: 0.8319\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 2s 48ms/step - loss: 0.2051 - accuracy: 0.9245 - val_loss: 0.4339 - val_accuracy: 0.8298\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.2002 - accuracy: 0.9263 - val_loss: 0.4551 - val_accuracy: 0.8277\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.1723 - accuracy: 0.9394 - val_loss: 0.5732 - val_accuracy: 0.8211\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.1543 - accuracy: 0.9462 - val_loss: 0.6210 - val_accuracy: 0.8199\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.1420 - accuracy: 0.9508 - val_loss: 0.6747 - val_accuracy: 0.8163\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.1289 - accuracy: 0.9565 - val_loss: 0.7313 - val_accuracy: 0.8165\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 2s 45ms/step - loss: 0.1255 - accuracy: 0.9553 - val_loss: 0.6820 - val_accuracy: 0.8145\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.1190 - accuracy: 0.9586 - val_loss: 0.6864 - val_accuracy: 0.8137\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.1051 - accuracy: 0.9633 - val_loss: 0.7056 - val_accuracy: 0.8125\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0997 - accuracy: 0.9653 - val_loss: 0.7213 - val_accuracy: 0.8073\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0860 - accuracy: 0.9703 - val_loss: 0.7729 - val_accuracy: 0.8081\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.8573 - val_accuracy: 0.8063\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0651 - accuracy: 0.9781 - val_loss: 0.9120 - val_accuracy: 0.8080\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0600 - accuracy: 0.9792 - val_loss: 1.0219 - val_accuracy: 0.8070\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0587 - accuracy: 0.9802 - val_loss: 1.0061 - val_accuracy: 0.8044\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0576 - accuracy: 0.9798 - val_loss: 1.0029 - val_accuracy: 0.8068\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 2s 51ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 1.0819 - val_accuracy: 0.8010\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 2s 48ms/step - loss: 0.0466 - accuracy: 0.9838 - val_loss: 1.1783 - val_accuracy: 0.8032\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0483 - accuracy: 0.9838 - val_loss: 1.1172 - val_accuracy: 0.8031\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 1.1726 - val_accuracy: 0.8007\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 1.2503 - val_accuracy: 0.7992\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 1.3346 - val_accuracy: 0.8007\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 1.4074 - val_accuracy: 0.8018\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 1.3875 - val_accuracy: 0.8035\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 1.3687 - val_accuracy: 0.7965\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 1.6167 - val_accuracy: 0.7997\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 1.2939 - val_accuracy: 0.8034\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 1.3549 - val_accuracy: 0.8032\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 1.4561 - val_accuracy: 0.8033\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 1.4186 - val_accuracy: 0.7992\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 1.4233 - val_accuracy: 0.8029\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0271 - accuracy: 0.9907 - val_loss: 1.4166 - val_accuracy: 0.8028\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 1.4061 - val_accuracy: 0.8032\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 1.6110 - val_accuracy: 0.8005\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 1.4964 - val_accuracy: 0.8020\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 1.5885 - val_accuracy: 0.8024\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 1.6163 - val_accuracy: 0.8027\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 1.7098 - val_accuracy: 0.8027\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 1.6712 - val_accuracy: 0.8008\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 1.6413 - val_accuracy: 0.8022\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 1.6972 - val_accuracy: 0.8009\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0231 - accuracy: 0.9919 - val_loss: 1.6890 - val_accuracy: 0.7999\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 1.8268 - val_accuracy: 0.7993\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 1.6095 - val_accuracy: 0.8003\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 1.8934 - val_accuracy: 0.7992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab98e83518>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练和验证\n",
    "model.fit(db_train, epochs=epochs, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 11ms/step - loss: 1.8934 - accuracy: 0.7992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8933717434604962, 0.79919434]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载预训练模型LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Indexing word vectors.')\n",
    "embeddings_index = {}\n",
    "GLOVE_DIR = r'C:\\Users\\sha\\AppData\\Roaming\\mxnet\\embeddings\\glove'\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 88584)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index.keys()),len(word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = total_words\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, embedding_len))\n",
    "applied_vec_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9796 (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    # print(word,embedding_vector)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        applied_vec_count += 1\n",
    "print(applied_vec_count, embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(keras.Model):\n",
    "    # Cell方式构建多层网络\n",
    "    def __init__(self, units):\n",
    "        super(MyLSTM, self).__init__() \n",
    "        # 词向量编码 [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len,\n",
    "                                          trainable=True)\n",
    "        self.embedding.build(input_shape=(None,max_review_len))\n",
    "        self.embedding.set_weights([embedding_matrix])\n",
    "        # 构建RNN\n",
    "        self.rnn = keras.Sequential([\n",
    "            layers.LSTM(units, dropout=0.5, return_sequences=True),\n",
    "            layers.LSTM(units, dropout=0.5)\n",
    "        ])\n",
    "        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "            layers.Dense(32),\n",
    "            layers.Dropout(rate=0.5),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(1)])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [b, 80]\n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        x = self.rnn(x)\n",
    "        # 末层最后一个输出作为分类网络的输入: [b, 64] => [b, 1]\n",
    "        x = self.outlayer(x,training)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 32 # RNN状态向量长度f\n",
    "epochs = 50 # 训练epochs\n",
    "\n",
    "model = MyLSTM(units)\n",
    "# 装配\n",
    "model.compile(optimizer = optimizers.Adam(0.001),\n",
    "              loss = losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "48/48 [==============================] - 10s 213ms/step - loss: 0.6937 - accuracy: 0.5037 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.6855 - accuracy: 0.5454 - val_loss: 0.7127 - val_accuracy: 0.5658\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.6423 - accuracy: 0.6464 - val_loss: 0.5879 - val_accuracy: 0.7035\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.5665 - accuracy: 0.7194 - val_loss: 0.5112 - val_accuracy: 0.7511\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.4956 - accuracy: 0.7725 - val_loss: 0.4571 - val_accuracy: 0.7846\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.4444 - accuracy: 0.8009 - val_loss: 0.4197 - val_accuracy: 0.8084\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.4140 - accuracy: 0.8194 - val_loss: 0.4040 - val_accuracy: 0.8179\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.3841 - accuracy: 0.8358 - val_loss: 0.3856 - val_accuracy: 0.8260\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.3558 - accuracy: 0.8507 - val_loss: 0.3842 - val_accuracy: 0.8315\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.3440 - accuracy: 0.8590 - val_loss: 0.3835 - val_accuracy: 0.8336\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.3283 - accuracy: 0.8640 - val_loss: 0.3732 - val_accuracy: 0.8352\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.3140 - accuracy: 0.8702 - val_loss: 0.3787 - val_accuracy: 0.8393\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.2998 - accuracy: 0.8766 - val_loss: 0.3862 - val_accuracy: 0.8395\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.2920 - accuracy: 0.8815 - val_loss: 0.3853 - val_accuracy: 0.8399\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.2833 - accuracy: 0.8871 - val_loss: 0.3753 - val_accuracy: 0.8414\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.2720 - accuracy: 0.8916 - val_loss: 0.3925 - val_accuracy: 0.8407\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.2624 - accuracy: 0.8927 - val_loss: 0.3986 - val_accuracy: 0.8410\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.2573 - accuracy: 0.8980 - val_loss: 0.3938 - val_accuracy: 0.8413\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.2473 - accuracy: 0.9016 - val_loss: 0.4093 - val_accuracy: 0.8406\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.2404 - accuracy: 0.9060 - val_loss: 0.4159 - val_accuracy: 0.8403\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.2352 - accuracy: 0.9073 - val_loss: 0.4243 - val_accuracy: 0.8403\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.2276 - accuracy: 0.9122 - val_loss: 0.4195 - val_accuracy: 0.8411\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.2261 - accuracy: 0.9119 - val_loss: 0.4160 - val_accuracy: 0.8400\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.2173 - accuracy: 0.9154 - val_loss: 0.4364 - val_accuracy: 0.8399\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.2097 - accuracy: 0.9167 - val_loss: 0.4585 - val_accuracy: 0.8390\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.2100 - accuracy: 0.9182 - val_loss: 0.4559 - val_accuracy: 0.8376\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.2060 - accuracy: 0.9222 - val_loss: 0.4824 - val_accuracy: 0.8365\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.2019 - accuracy: 0.9220 - val_loss: 0.4481 - val_accuracy: 0.8358\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.1928 - accuracy: 0.9258 - val_loss: 0.4807 - val_accuracy: 0.8375\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.1889 - accuracy: 0.9287 - val_loss: 0.4939 - val_accuracy: 0.8376\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.1803 - accuracy: 0.9301 - val_loss: 0.5268 - val_accuracy: 0.8353\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 3s 63ms/step - loss: 0.1791 - accuracy: 0.9306 - val_loss: 0.4964 - val_accuracy: 0.8348\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.1775 - accuracy: 0.9318 - val_loss: 0.5444 - val_accuracy: 0.8338\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.1728 - accuracy: 0.9329 - val_loss: 0.5388 - val_accuracy: 0.8348\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.1703 - accuracy: 0.9370 - val_loss: 0.4979 - val_accuracy: 0.8344\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.1642 - accuracy: 0.9385 - val_loss: 0.5954 - val_accuracy: 0.8319\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.1644 - accuracy: 0.9379 - val_loss: 0.6031 - val_accuracy: 0.8323\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.1622 - accuracy: 0.9390 - val_loss: 0.5753 - val_accuracy: 0.8324\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 3s 67ms/step - loss: 0.1521 - accuracy: 0.9432 - val_loss: 0.5685 - val_accuracy: 0.8319\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.1493 - accuracy: 0.9457 - val_loss: 0.5786 - val_accuracy: 0.8322\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.1490 - accuracy: 0.9439 - val_loss: 0.5897 - val_accuracy: 0.8317\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.1430 - accuracy: 0.9442 - val_loss: 0.5969 - val_accuracy: 0.8332\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.1423 - accuracy: 0.9472 - val_loss: 0.5893 - val_accuracy: 0.8315\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.1399 - accuracy: 0.9495 - val_loss: 0.6657 - val_accuracy: 0.8289\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.1338 - accuracy: 0.9489 - val_loss: 0.6216 - val_accuracy: 0.8312\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 3s 65ms/step - loss: 0.1337 - accuracy: 0.9509 - val_loss: 0.6579 - val_accuracy: 0.8313\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.1288 - accuracy: 0.9516 - val_loss: 0.6661 - val_accuracy: 0.8307\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.1246 - accuracy: 0.9534 - val_loss: 0.6794 - val_accuracy: 0.8308\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.1199 - accuracy: 0.9569 - val_loss: 0.7093 - val_accuracy: 0.8295\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 3s 66ms/step - loss: 0.1195 - accuracy: 0.9549 - val_loss: 0.6964 - val_accuracy: 0.8309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c387f49048>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练和验证\n",
    "model.fit(db_train, epochs=epochs, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 17ms/step - loss: 0.6964 - accuracy: 0.8309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6964077167212963, 0.8308919]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Cell构建基本RNN文本情感分析网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNNCell(keras.Model):\n",
    "    # Cell方式构建多层网络\n",
    "    def __init__(self, units):\n",
    "        super(MyRNNCell, self).__init__()\n",
    "        # [b, 64]，构建Cell初始化状态向量，重复使用\n",
    "        self.state0 = [tf.zeros([batchsz, units])]\n",
    "        self.state1 = [tf.zeros([batchsz, units])]\n",
    "        # 词向量编码 [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # 构建2个Cell\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.Dropout(rate=0.5),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(1)])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [b, 80]\n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        state0 = self.state0\n",
    "        state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1): # word: [b, 100] \n",
    "            out0, state0 = self.rnn_cell0(word, state0, training) \n",
    "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
    "        # 末层最后一个输出作为分类网络的输入: [b, 64] => [b, 1]\n",
    "        x = self.outlayer(out1, training)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64 # RNN状态向量长度f\n",
    "epochs = 2 # 训练epochs\n",
    "\n",
    "model = MyRNNCell(units)\n",
    "# 装配\n",
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "              loss = losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 80) (512,)\n",
      "(512, 80) (512,)\n"
     ]
    }
   ],
   "source": [
    "for x,y in db_train:\n",
    "    print(x.shape,y.shape)\n",
    "    break\n",
    "for x,y in db_test:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "      1/Unknown - 5s 5s/step"
     ]
    },
    {
     "ename": "_SymbolicException",
     "evalue": "Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'my_rnn_cell/simple_rnn_cell_8/cond/Identity:0' shape=(None, 100) dtype=float32>, <tf.Tensor 'my_rnn_cell/simple_rnn_cell_9/cond/Identity:0' shape=(512, 64) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: my_rnn_cell/simple_rnn_cell_8/cond/Identity:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-c03931c51918>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     73\u001b[0m       raise core._SymbolicException(\n\u001b[0;32m     74\u001b[0m           \u001b[1;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'my_rnn_cell/simple_rnn_cell_8/cond/Identity:0' shape=(None, 100) dtype=float32>, <tf.Tensor 'my_rnn_cell/simple_rnn_cell_9/cond/Identity:0' shape=(512, 64) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "model.fit(db_train, epochs=epochs, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Cell构建基本RNN文本情感分析网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNNCell(keras.Model):\n",
    "    # Cell\n",
    "    def __init__(self, units):\n",
    "        super(MyRNNCell, self).__init__()\n",
    "        # [b, 64]\n",
    "        self.state0 = [tf.zeros([batchsz, units])]\n",
    "        self.state1 = [tf.zeros([batchsz, units])]\n",
    "        #  [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
    "                                          input_length=max_review_len)\n",
    "        # 构建2个Cell\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.Dropout(rate=0.5),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(1)])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [b, 80]\n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        state0 = self.state0\n",
    "        state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1): # word: [b, 100] \n",
    "            out0, state0 = self.rnn_cell0(word, state0, training) \n",
    "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
    "        # [b, 64] => [b, 1]\n",
    "        x = self.outlayer(out1, training)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64 # RNN\n",
    "epochs = 2 # epochs\n",
    "\n",
    "model = MyRNNCell(units)\n",
    "# \n",
    "# model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "#               loss = losses.BinaryCrossentropy(),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 80) (128,)\n",
      "(128, 80) (128,)\n"
     ]
    }
   ],
   "source": [
    "for x,y in db_train:\n",
    "    print(x.shape,y.shape)\n",
    "    break\n",
    "for x,y in db_test:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.experimental_run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_object(y, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(test_x, test_y):\n",
    "    predictions = model(test_x)\n",
    "    t_loss = loss_object(test_y, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: my_rnn_cell_12/simple_rnn_cell_36/ones_like:0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-d59a3afffc48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdb_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdb_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     74\u001b[0m           \u001b[1;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: my_rnn_cell_12/simple_rnn_cell_36/ones_like:0"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for x, y in db_train:\n",
    "        train_step(x, y)\n",
    "\n",
    "    for test_x, test_y in db_test:\n",
    "        test_step(test_x, test_y)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {:.4f}, Accuracy: {:.4f}, Test Loss: {:.4f}, Test Accuracy: {:.4f}'\n",
    "    print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
